{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11081302,"sourceType":"datasetVersion","datasetId":6888932}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":9,"nbformat":5,"cells":[{"id":"9a419038-b3ac-41ca-b9ba-57f3082a47f0","cell_type":"code","source":"# Notebook Name: Generate_CoT_Sentiment_Analysis.ipynb\n# Import necessary libraries\nimport os\nimport time\nfrom tqdm import tqdm\nfrom openai import OpenAI\nfrom datasets import load_dataset, Value\nfrom huggingface_hub import login","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:41.730532Z","start_time":"2025-03-23T06:13:35.013406Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:54:04.607946Z","iopub.execute_input":"2025-03-29T12:54:04.608257Z","iopub.status.idle":"2025-03-29T12:54:07.871236Z","shell.execute_reply.started":"2025-03-29T12:54:04.608196Z","shell.execute_reply":"2025-03-29T12:54:07.870373Z"}},"outputs":[],"execution_count":1},{"id":"2cdd58e1-f9fa-4473-9c06-97cbe8e956e4","cell_type":"code","source":"!pip install openai\n\n# 在代码开头添加正确的导入\nfrom openai import OpenAI ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:54:16.224479Z","iopub.execute_input":"2025-03-29T12:54:16.224813Z","iopub.status.idle":"2025-03-29T12:54:20.874382Z","shell.execute_reply.started":"2025-03-29T12:54:16.224785Z","shell.execute_reply":"2025-03-29T12:54:20.873472Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.29.0)\n","output_type":"stream"}],"execution_count":2},{"id":"50982744-dad1-47e3-987c-ec8718424410","cell_type":"code","source":"import json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:54:40.787961Z","iopub.execute_input":"2025-03-29T12:54:40.788281Z","iopub.status.idle":"2025-03-29T12:54:40.792278Z","shell.execute_reply.started":"2025-03-29T12:54:40.788257Z","shell.execute_reply":"2025-03-29T12:54:40.791349Z"}},"outputs":[],"execution_count":3},{"id":"d225b76b-b6b9-4af4-822b-33a96a82135c","cell_type":"code","source":"# # Load API keys from environment variables\n# api_key = os.getenv(\"DeepSeek_API_KEY\")\n# hf_token = os.getenv(\"HF_TOKEN\")\n#\n# # Ensure API keys are available\n# if not api_key or not hf_token:\n#     raise ValueError(\"Missing API keys! Set 'DeepSeek_API_KEY' and 'HF_TOKEN' as environment variables.\")","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:41.746207Z","start_time":"2025-03-23T06:13:41.730532Z"}},"outputs":[],"execution_count":2},{"id":"6694f7da-be14-41b8-8f9f-64d1ee01455b","cell_type":"code","source":"# Load API keys from Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\n\n\ndef load_kaggle_secrets():\n    \"\"\"\n    Load API keys from Kaggle Secrets.\n    \"\"\"\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"DeepSeek_API_KEY\")\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n    return api_key, hf_token\n\n\n# Load API keys\napi_key, hf_token = load_kaggle_secrets()\n\n# Ensure API keys are available\nif not api_key or not hf_token:\n    raise ValueError(\"Missing API keys! Add 'DeepSeek_API_KEY' and 'HF_TOKEN' to your Kaggle Secrets.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:54:46.216888Z","iopub.execute_input":"2025-03-29T12:54:46.217179Z","iopub.status.idle":"2025-03-29T12:54:46.500876Z","shell.execute_reply.started":"2025-03-29T12:54:46.217158Z","shell.execute_reply":"2025-03-29T12:54:46.500237Z"}},"outputs":[],"execution_count":4},{"id":"506cd7e4-cdce-40f4-a263-ac1535537fa6","cell_type":"code","source":"# Function to initialize the API client\ndef initialize_api_client(api_key):\n    \"\"\"\n    Initialize the OpenAI client with DeepSeek API.\n    \"\"\"\n    return OpenAI(\n        api_key=api_key,\n        base_url=\"https://api.deepseek.com\"\n    )","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:41.769771Z","start_time":"2025-03-23T06:13:41.753330Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:54:51.445569Z","iopub.execute_input":"2025-03-29T12:54:51.445901Z","iopub.status.idle":"2025-03-29T12:54:51.449735Z","shell.execute_reply.started":"2025-03-29T12:54:51.445875Z","shell.execute_reply":"2025-03-29T12:54:51.448695Z"}},"outputs":[],"execution_count":5},{"id":"60c665eb-7d12-42ec-9237-388421af6716","cell_type":"code","source":"def generate_bias_cot(client, item, max_retries=3):\n    bias_types = [\n        \"AC（职业活动刻板印象）\",\n        \"DI（描述归纳偏见）\", \n        \"ANB（态度规范偏见）\"\n    ]\n    \n    prompt = f\"\"\"请按照以下框架分析文本的性别偏见：\n\n【任务说明】\n1. 偏见检测：判断文本是否包含性别偏见 (B/N)\n2. 偏见分类：若存在偏见，按三类标注 (AC/DI/ANB)\n3. 偏见缓解：生成无偏见的修改版本\n\n【分类标准】\n- AC (职业活动刻板印象): 将职业/活动与性别绑定 (例：\"护士应该由女性担任\")\n- DI (描述归纳偏见): 基于性别的特征归纳 (例：\"男生都不擅长文科\")\n- ANB (态度规范偏见): 传达性别不平等观念 (例：\"女孩就该文静听话\")\n\n【分析步骤】\n1. 识别所有性别相关表述\n2. 逐句分析偏见存在性\n3. 分类标记偏见类型\n4. 生成无偏见修改方案\n【示例输入】\n原始文本：这思想开始火焰似的把她燃烧起来了，她再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\n【期望输出】\n{{\n    \"ori_sentence\": \"这思想开始火焰似的把她燃烧起来了，她再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n    \"is_biased\": true,\n    \"bias_labels\": [0, 1, 0],  # AC=0, DI=1, ANB=0\n    \"edit_sentence\": \"这思想开始火焰似的燃烧起来了，主角再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n}}\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            response = client.chat.completions.create(\n                model=\"deepseek-chat\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"您是性别偏见分析专家，擅长判断性别偏见以及分类及改写性别偏见\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.4,  # 降低随机性保证分析准确性\n                max_tokens=500,\n                stream=False\n            )\n            analysis = response.choices[0].message.content.strip()\n            \n            # 添加结构化结论\n            conclusion = \"\\n\\n结论：\\n\" + \"\\n\".join(\n                [f\"{bias_types[i]}: {label}\" for i, label in enumerate(item['bias_labels'])]\n            )\n            return analysis + conclusion\n        except Exception as e:\n            if attempt < max_retries - 1:\n                print(f\"Attempt {attempt+1} failed, retrying...\")\n                time.sleep(2)\n            else:\n                print(f\"Failed after {max_retries} attempts: {str(e)}\")\n                return \"CoT generation failed\"\n    if \"结论：\" not in analysis:\n        analysis += \"\\n结论：\\n\" + \"\\n\".join(\n            [f\"{bias_types[i]}: {label}\" for i, label in enumerate(item['bias_labels'])]\n        )\n    return analysis","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:42.173502Z","start_time":"2025-03-23T06:13:42.155873Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:59:44.632663Z","iopub.execute_input":"2025-03-29T13:59:44.632981Z","iopub.status.idle":"2025-03-29T13:59:44.639814Z","shell.execute_reply.started":"2025-03-29T13:59:44.632959Z","shell.execute_reply":"2025-03-29T13:59:44.638860Z"}},"outputs":[],"execution_count":41},{"id":"9a4b59ec-27ca-4340-8372-adf95ab49eb0","cell_type":"code","source":"def load_data(biased_path, neutral_path):\n    \"\"\"加载带有详细元数据的偏见数据集\"\"\"\n    from datasets import Dataset\n    data = []\n    \n    # 加载偏见数据（包含完整元数据）\n    with open(biased_path, 'r', encoding='utf-8-sig') as f:\n        for item in json.load(f):\n            record = {\n                'original_text': item['ori_sentence'],\n                'edited_text': item['edit_sentence'],\n                'bias_labels': item['bias_labels'],\n                'text_type': 'biased'\n            }\n            data.append(record)\n    \n    # 加载中性数据（补充必要字段）\n    with open(neutral_path, 'r', encoding='utf-8-sig') as f:\n        for item in json.load(f):\n            record = {\n                'original_text': item['text'],\n                'edited_text': None,\n                'bias_labels': [0, 0, 0],\n                'text_type': 'neutral'\n            }\n            data.append(record)\n    \n    return Dataset.from_list(data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T12:55:00.376882Z","iopub.execute_input":"2025-03-29T12:55:00.377211Z","iopub.status.idle":"2025-03-29T12:55:00.383108Z","shell.execute_reply.started":"2025-03-29T12:55:00.377190Z","shell.execute_reply":"2025-03-29T12:55:00.382171Z"}},"outputs":[],"execution_count":7},{"id":"8e5eb1b5-6417-4972-9181-ca96a90ec945","cell_type":"code","source":"def add_cot_to_dataset(client, dataset, sample_size=1000):\n    \"\"\"完全正确的缩进版本\"\"\"\n    # ↓ 第1级缩进（4空格）\n    if sample_size and len(dataset) > sample_size:\n        # ↓ 第2级缩进（8空格）\n        dataset = dataset.select(range(sample_size))\n    \n    # ↓ 保持第1级缩进\n    cots = []\n    for item in tqdm(dataset):\n        cot = generate_bias_cot(client, item)\n        cots.append(cot)\n    \n    # ↓↓↓ 关键修改：统一使用Bias_Analysis_CoT作为列名 ↓↓↓\n    return dataset.add_column(\"Bias_Analysis_CoT\", cots) \n\n","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:42.220771Z","start_time":"2025-03-23T06:13:42.207102Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:15:28.755733Z","iopub.execute_input":"2025-03-29T13:15:28.756092Z","iopub.status.idle":"2025-03-29T13:15:28.760800Z","shell.execute_reply.started":"2025-03-29T13:15:28.756066Z","shell.execute_reply":"2025-03-29T13:15:28.759868Z"}},"outputs":[],"execution_count":28},{"id":"1fe91d23-3bd6-4a81-8806-75b290d21631","cell_type":"code","source":"biased_path = \"/kaggle/input/pianjian/biased.json\" \nneutral_path = \"/kaggle/input/pianjian/non-biased.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:00:20.328384Z","iopub.execute_input":"2025-03-29T13:00:20.328662Z","iopub.status.idle":"2025-03-29T13:00:20.332371Z","shell.execute_reply.started":"2025-03-29T13:00:20.328642Z","shell.execute_reply":"2025-03-29T13:00:20.331425Z"}},"outputs":[],"execution_count":15},{"id":"3d01af5a-da4d-4752-9f71-c8890ec8f8a3","cell_type":"code","source":"\n# 修改上传函数中的列名（将Complex_CoT改为Bias_Analysis_CoT）\ndef upload_to_huggingface(dataset, repo_id, hf_token, is_private=True):\n    \"\"\"将数据集上传到Hugging Face Hub\"\"\"\n    login(token=hf_token)\n    \n    # 确保字段名称与实际列名一致\n    dataset = dataset.cast_column(\"Bias_Analysis_CoT\", Value(\"string\"))  # 修改这里\n    \n    dataset.push_to_hub(\n        repo_id=repo_id,\n        token=hf_token,\n        private=is_private,\n        commit_message=\"Add CoT annotations\"\n    )\n    print(f\"✅ 数据集已上传至: https://huggingface.co/datasets/{repo_id}\")\n\n# 验证数据集列名\nprint(\"数据集列名:\", enhanced_dataset.column_names)\n# 应输出: ['original_text', 'edited_text', 'bias_labels', 'text_type', 'Bias_Analysis_CoT']","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:42.257524Z","start_time":"2025-03-23T06:13:42.238530Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:08:09.320558Z","iopub.execute_input":"2025-03-29T13:08:09.320867Z"}},"outputs":[{"name":"stderr","text":"生成CoT分析: 100%|██████████| 1/1 [00:21<00:00, 21.25s/it]","output_type":"stream"}],"execution_count":null},{"id":"5f0970d4-b992-4da6-be71-8b43571b6b12","cell_type":"code","source":"# 修改函数定义（添加sample_size参数）\ndef create_cot_dataset(api_key, hf_token, dataset_name, \n                      biased_path, neutral_path, \n                      sample_size=None):  # 新增参数\n    client = initialize_api_client(api_key)\n    \n    # 加载数据\n    dataset = load_data(biased_path, neutral_path)\n    \n    # 传递sample_size给处理函数\n    enhanced_dataset = add_cot_to_dataset(\n        client=client,\n        dataset=dataset,\n        sample_size=sample_size  # 传递参数\n    )\n    \n    upload_to_huggingface(enhanced_dataset, dataset_name, hf_token)\n    return enhanced_dataset\ndataset_name = \"pianjian/pianjian-with-cot\"\n\n# 正确调用方式（包含sample_size）\nenhanced_dataset = create_cot_dataset(\n    api_key=api_key,\n    hf_token=hf_token,\n    dataset_name=dataset_name,\n    biased_path=biased_path,\n    neutral_path=neutral_path,\n    sample_size=1000 # 指定处理1000条数据\n)\n\n","metadata":{"ExecuteTime":{"end_time":"2025-03-23T06:13:42.289453Z","start_time":"2025-03-23T06:13:42.275408Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:15:14.441484Z","iopub.execute_input":"2025-03-29T14:15:14.441923Z","iopub.status.idle":"2025-03-29T17:36:44.710051Z","shell.execute_reply.started":"2025-03-29T14:15:14.441889Z","shell.execute_reply":"2025-03-29T17:36:44.709154Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [3:21:25<00:00, 12.09s/it] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77eec3d6f7a142c89305df0d02fe9516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da62b18f464444fa37c52b69e850988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36a8af6abb814062a38c9fac324a7546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"765bfa417b9e4cb4ac703a2f4c03765d"}},"metadata":{}},{"name":"stdout","text":"✅ 数据集已上传至: https://huggingface.co/datasets/pianjian/pianjian-with-cot\n","output_type":"stream"}],"execution_count":44},{"id":"511c51d8-3b4e-4fad-bc05-f86ed4c76c15","cell_type":"code","source":"\nsample_cot = enhanced_dataset[0]['Bias_Analysis_CoT']\nprint(\"\\n示例CoT分析:\\n\", sample_cot)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:00:11.428365Z","iopub.execute_input":"2025-03-29T14:00:11.428684Z","iopub.status.idle":"2025-03-29T14:00:11.434217Z","shell.execute_reply.started":"2025-03-29T14:00:11.428655Z","shell.execute_reply":"2025-03-29T14:00:11.433261Z"}},"outputs":[{"name":"stdout","text":"\n示例CoT分析:\n 让我来分析这段文本：\n\n{\n    \"ori_sentence\": \"这思想开始火焰似的把她燃烧起来了，她再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n    \"is_biased\": true,\n    \"bias_labels\": [0, 1, 0],  # AC=0, DI=1, ANB=0\n    \"edit_sentence\": \"这思想开始火焰似的燃烧起来了，主角再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n}\n\n分析说明：\n1. 偏见检测(B/N)：存在偏见(B)\n2. 偏见分类：\n   - AC(职业活动刻板印象)：0(不存在)\n   - DI(描述归纳偏见)：1(存在) - 将\"虚荣\"、\"矜持\"等特质特别与女性(\"她\")关联\n   - ANB(态度规范偏见)：0(不存在)\n3. 修改方案：\n   - 移除性别代词\"她\"\n   - 使用中性词\"主角\"替代\n   - 保留情感表达但去除性别关联\n\n修改后的版本消除了将特定情感特质与女性绑定的刻板印象，使描述更具普遍性。\n\n结论：\nAC（职业活动刻板印象）: 0\nDI（描述归纳偏见）: 1\nANB（态度规范偏见）: 0\n","output_type":"stream"}],"execution_count":43}]}